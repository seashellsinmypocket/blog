+++ date = '2025-08-04T20:48:12-07:00' draft = true title = 'Attention is all you need' tags = ['adhd', 'life', 'attention economy', 'llm', 'metaphor'] +++

I was recently asked to write a guest post at work about my thoughts on AI coding tools. My day job is of a Senior Software Engineer at a mid size company.I wrote the article about my reflections about AI and LLM usage. I had a paragraph on the attention economy but
after thinking about it, I deleted it from my final draft. The advice was too personal for a professional setting. I will write about some of those thoughts here and add some more while I am at it.

A foundational paper in Large Language Models is "Attention is all you need" by Googe Research. You may have seen the term used in several places and when other research papers that make a reference the original paper. The paper is about the Transformer Architecture Used in LLMs that helped increase quality and reduced the time to train the models.
In "Attention is All You Need", the attention mechanism allows the model to weigh the importance of different parts of the input sequence when processing it. This enables the model to focus on the most relevant parts for a given task, improving both efficiency and accuracy. The mechanism dynamically assigns weights to various sequence positions, mirroring how humans focus on specific elements within a sequence. 
It is interesting that the attention mechanism used to increase the efficiency and accuracy of the models also creates this hook to grab our attention by using dark pattern like sycophancy.

I am reading of people spending hours of their leisure time experimenting with all the new shiny AI tools. Burning through tokens with an insatiable hungry. I get it. They are fueled by the dopamine hit of creating something themselves. So quickly for what it is worth, too. I experienced the same recently when I finally decided to embrace AI coding tools after carefully considering the impact of it on my critical thinking skills. That was all I did for over two weeks. Days of forgetting about lunch or dinner. I had a deadline to meet and things to prove out. The proof of concept worked well in the end.
But I didn't like how I felt. I felt drained. I was happy with what I built. But it almost feels like the dopamine hit effect is inversely proportional to the effort taken to get to the results. So the more quickly I got something to work, the lesser the dopamine hit. I want back the days of struggling to figure out a gnarly bug for days and finally feeling the sense of achievement when I fixed it. I want to spend a lot of time searching through StackOverflow and trying to find someone with the similar issue that I was currently facing to look for clues that will help me fix the bug. My need for cognition was satisfied with those struggles and searches. I don't feel that anymore.

Our attention is also being pulled in so many different ways with our devices. What it this AI age the beginning days of for the attention economy? How many people in an elevator are checking their phones? I am guilty of that too. And I hate it. 

In my work article, I wanted to advice people against spending their leisure time with AI. I wanted to encourage them to spend more time with their family or friends. Spend time out in nature. Spend time with things that make your soul happy. But who am I to give other people advice when I don't take heed to my own advice? What if spending leisure time with AI is making their soul happy?

I need to remind myself often that life is short and life is to be enjoyed and life is full of awe waiting to be discovered. So for now I am taking my own advice. I am slowing down and enjoying the present moment. My meditiation is watching all the AI codiing tool come and go.
I can take control of how I use these tools and how I live my life.

Attention is all I need to live a meaningful life.
